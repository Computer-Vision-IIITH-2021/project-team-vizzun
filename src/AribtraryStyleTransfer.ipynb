{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AribtraryStyleTransfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ5Jhlq2JhUh"
      },
      "source": [
        "##Arbitrary Style Transfer Code"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzkpnzXYo5RT"
      },
      "source": [
        "Importing all the modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOMwe8hqn-J5"
      },
      "source": [
        "import numpy as np\n",
        "from os import listdir, mkdir, sep\n",
        "from os.path import join, exists, splitext\n",
        "import cv2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owqEAPrx24gO"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjNrXBk2tLYC"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq8bJEhBnHqH"
      },
      "source": [
        "# !wget http://images.cocodataset.org/zips/test2014.zip\n",
        "# !unzip *.zip\n",
        "# !rm *.zip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU-BvhqiY4x_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTwyY_KotefY",
        "outputId": "df859733-cb07-4cd0-af54-45d32fddb70a"
      },
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.6.0', 'vgg19', pretrained=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tarTGdYpGo8",
        "outputId": "0864947f-506d-4e86-b515-3deab6783662"
      },
      "source": [
        "!mkdir -p test2014/1\n",
        "!mv test2014/*.jpg test2014/1/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'test2014/*.jpg': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5W8NcfScO_I"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb50baPKtfeK",
        "outputId": "12ec41af-b4bb-4c3d-f076-73cb344f2b41"
      },
      "source": [
        "enc=nn.Sequential(*list(model.features.children())[:21])\n",
        "for i in enc.parameters():\n",
        "  i.requires_grad = False\n",
        "enc"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (3): ReLU(inplace=True)\n",
              "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (6): ReLU(inplace=True)\n",
              "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (8): ReLU(inplace=True)\n",
              "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): ReLU(inplace=True)\n",
              "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (13): ReLU(inplace=True)\n",
              "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (15): ReLU(inplace=True)\n",
              "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (17): ReLU(inplace=True)\n",
              "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (20): ReLU(inplace=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qryupYSBtjBb"
      },
      "source": [
        "# Use Sequential to define decoder [Just reverse of vgg with pooling replaced by nearest neigbour upscaling]\n",
        "dec = nn.Sequential(\n",
        "nn.Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect' ),\n",
        "nn.ReLU(),\n",
        "nn.Upsample(scale_factor=2,mode='nearest'),\n",
        "nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
        "nn.ReLU(),\n",
        "nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
        "nn.ReLU(),\n",
        "nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
        "nn.ReLU(),\n",
        "nn.Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
        "nn.ReLU(),\n",
        "nn.Upsample(scale_factor=2,mode='nearest'),\n",
        "nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
        "nn.ReLU(),\n",
        "nn.Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
        "nn.ReLU(),\n",
        "nn.Upsample(scale_factor=2,mode='nearest'),\n",
        "nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
        "nn.ReLU(),\n",
        "nn.Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
        "nn.ReLU()\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emzXzsFPt78s",
        "outputId": "4b2a205f-478f-46e0-deac-9e803c3f4836"
      },
      "source": [
        "dec"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "  (1): ReLU()\n",
              "  (2): Upsample(scale_factor=2.0, mode=nearest)\n",
              "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "  (4): ReLU()\n",
              "  (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "  (6): ReLU()\n",
              "  (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "  (8): ReLU()\n",
              "  (9): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "  (10): ReLU()\n",
              "  (11): Upsample(scale_factor=2.0, mode=nearest)\n",
              "  (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "  (13): ReLU()\n",
              "  (14): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "  (15): ReLU()\n",
              "  (16): Upsample(scale_factor=2.0, mode=nearest)\n",
              "  (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "  (18): ReLU()\n",
              "  (19): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "  (20): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-lTnT-BuAL9"
      },
      "source": [
        "# pipeline"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1Ec6ZIlv5yJ"
      },
      "source": [
        "class Encoder_Decoder(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.style_features = []\n",
        "    self.style_layers = [1, 6, 11, 20] # relu1_1, relu2_1, relu3_1, relu4_1\n",
        "    for i in self.style_layers:\n",
        "      self.encoder._modules[str(i)].register_forward_hook(self.style_feature_hook)\n",
        "\n",
        "  def style_feature_hook(self, module, input, output):\n",
        "    self.style_features.append(output)\n",
        "\n",
        "  def forward(self, image):\n",
        "\n",
        "    self.content_in = self.encoder(image)\n",
        "    self.style_features = []\n",
        "\n",
        "    return self.decoder(self.content_in)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00Aid-G22BDJ"
      },
      "source": [
        "def read_image(path, size=None, gray=False):\n",
        "    img = cv2.imread(path)\n",
        "    if gray:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    if size != None:\n",
        "        img = cv2.resize(img, size)\n",
        "    return img"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLpDaKVI2J-V"
      },
      "source": [
        "from PIL import Image\n",
        "# lion = Image.open('drive/MyDrive/images/style/1/lion.jpg')\n",
        "# lion = Image.open('https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fs-media-cache-ak0.pinimg.com%2Foriginals%2Fad%2F21%2F86%2Fad2186c3301997a31780d5ab600d71c9.jpg&f=1&nofb=1')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLgGPf0j26No"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.Lambda(lambda x: x.to(device))\n",
        "])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0ryq0L-pZec"
      },
      "source": [
        "enc = enc.to(device)\n",
        "dec = dec.to(device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9tHHIBYJ9Kk"
      },
      "source": [
        "# train = DataLoader(ImageFolder('drive/MyDrive/images/content', transform=preprocess), batch_size=1, shuffle=True, num_workers=0)\n",
        "# test = DataLoader(ImageFolder('drive/MyDrive/images/style', transform=preprocess), batch_size=1, shuffle=True, num_workers=0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ohgxrdgN5C_"
      },
      "source": [
        "# x = 0\n",
        "# for i in train:\n",
        "#   save_image(i[0], f\"{x}.jpg\")\n",
        "#   plt.imshow(Image.open(f\"{x}.jpg\"))\n",
        "#   plt.show()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z45iJeO7Ovfh"
      },
      "source": [
        "# x = 0\n",
        "# for i in test:\n",
        "#   save_image(i[0], f\"{x}.jpg\")\n",
        "#   plt.imshow(Image.open(f\"{x}.jpg\"))\n",
        "#   plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILgtz_z0D4IA"
      },
      "source": [
        "def trainModel(Model, Loss, trainImagesPath, testImagesPath, batchSize=1, epochs=5, learningRate=6e-4, weightDecay=1e-3, alpha=0.1):\n",
        "\n",
        "  train_images = DataLoader(ImageFolder(trainImagesPath, transform=preprocess), batch_size=batchSize, shuffle=True, num_workers=0)\n",
        "  # test_images = DataLoader(ImageFolder(testImagesPath, transform=preprocess), batch_size=batchSize, shuffle=True, num_workers=0)\n",
        "\n",
        "  model = Model(enc, dec).to(device)\n",
        "  loss_fn = Loss().to(device)\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learningRate, weight_decay=weightDecay)\n",
        "\n",
        "  for e in range(epochs):\n",
        "    epoch_loss = 0.0\n",
        "    i=0.0\n",
        "    for img in train_images:\n",
        "      img = img[0]\n",
        "      i+=1\n",
        "      if(i > 100): \n",
        "        break\n",
        "      print(\"\\r\", i, end=\"\")\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      decoded = model(img)\n",
        "    \n",
        "      content_in = model.encoder(img)\n",
        "      content_out = model.encoder(decoded)\n",
        "      styles_in = model.style_features[:4]\n",
        "      styles_out = model.style_features[4:]\n",
        "\n",
        "      loss = loss_fn(content_in, content_out, styles_in, styles_out)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "      del content_in, content_out, styles_in, styles_out, decoded, loss\n",
        "      # save_image(decoded, f\"tmp_{i}.jpg\")\n",
        "    print(\"\\nEpoch\", e, end=\": \")\n",
        "    print(\"Epoch Loss = \", epoch_loss/len(train_images))\n",
        "\n",
        "  \n",
        "  torch.save(model.state_dict(), 'enc_dec_model')\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRLbGdmaSwDR"
      },
      "source": [
        "class ContentStyleLoss(nn.Module):\n",
        "  def __init__(self, lam=0.5):\n",
        "    super().__init__()\n",
        "    self.lam = lam\n",
        "\n",
        "  def forward (self, content_in, content_out, styles_in, styles_out):\n",
        "    contentLoss = torch.norm(content_out - content_in)\n",
        "    styleLoss = np.sum([\n",
        "                           torch.linalg.norm(torch.mean(styles_out[i], (2, 3)) - torch.mean(styles_in[i], (2,3))) + \n",
        "                           torch.linalg.norm(torch.std(styles_out[i], axis=(2, 3), unbiased=False) - torch.std(styles_in[i], axis=(2, 3), unbiased=False)) \n",
        "                           for i in range(len(styles_in))\n",
        "    ])\n",
        "\n",
        "    return contentLoss + self.lam*styleLoss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GtZtLzaTVNp",
        "outputId": "fd5180c3-0135-4251-e4b1-74e5c03ef6b8"
      },
      "source": [
        "md = trainModel(Encoder_Decoder, ContentStyleLoss, 'test2014', 'drive/MyDrive/images/style', epochs=100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 100.0\n",
            "Epoch 0: Epoch Loss =  7.406206860007281\n",
            " 100.0\n",
            "Epoch 1: Epoch Loss =  6.699786045394888\n",
            " 100.0\n",
            "Epoch 2: Epoch Loss =  6.268280286011266\n",
            " 100.0\n",
            "Epoch 3: Epoch Loss =  6.094792484959381\n",
            " 100.0\n",
            "Epoch 4: Epoch Loss =  6.0685850681138875\n",
            " 100.0\n",
            "Epoch 5: Epoch Loss =  6.011116146272418\n",
            " 100.0\n",
            "Epoch 6: Epoch Loss =  5.711828028002376\n",
            " 100.0\n",
            "Epoch 7: Epoch Loss =  5.739946423781422\n",
            " 100.0\n",
            "Epoch 8: Epoch Loss =  5.576249591352602\n",
            " 100.0\n",
            "Epoch 9: Epoch Loss =  5.470968141070471\n",
            " 100.0\n",
            "Epoch 10: Epoch Loss =  5.517062010820624\n",
            " 100.0\n",
            "Epoch 11: Epoch Loss =  5.477181994486703\n",
            " 100.0\n",
            "Epoch 12: Epoch Loss =  5.405483446337561\n",
            " 100.0\n",
            "Epoch 13: Epoch Loss =  5.533116719276901\n",
            " 100.0\n",
            "Epoch 14: Epoch Loss =  5.448136079882932\n",
            " 100.0\n",
            "Epoch 15: Epoch Loss =  5.429241176209955\n",
            " 100.0\n",
            "Epoch 16: Epoch Loss =  5.326064327387339\n",
            " 100.0\n",
            "Epoch 17: Epoch Loss =  5.196048619160982\n",
            " 100.0\n",
            "Epoch 18: Epoch Loss =  5.278502362670524\n",
            " 100.0\n",
            "Epoch 19: Epoch Loss =  5.077068604563439\n",
            " 100.0\n",
            "Epoch 20: Epoch Loss =  5.245017447597333\n",
            " 100.0\n",
            "Epoch 21: Epoch Loss =  5.151209385238638\n",
            " 100.0\n",
            "Epoch 22: Epoch Loss =  5.093261347524525\n",
            " 100.0\n",
            "Epoch 23: Epoch Loss =  5.168769501312462\n",
            " 100.0\n",
            "Epoch 24: Epoch Loss =  5.089468782332541\n",
            " 100.0\n",
            "Epoch 25: Epoch Loss =  5.17062782011611\n",
            " 100.0\n",
            "Epoch 26: Epoch Loss =  4.951262340253296\n",
            " 100.0\n",
            "Epoch 27: Epoch Loss =  5.176415045648758\n",
            " 100.0\n",
            "Epoch 28: Epoch Loss =  4.850167804392915\n",
            " 100.0\n",
            "Epoch 29: Epoch Loss =  5.07542014041903\n",
            " 100.0\n",
            "Epoch 30: Epoch Loss =  4.97842149239826\n",
            " 100.0\n",
            "Epoch 31: Epoch Loss =  4.896790923417382\n",
            " 100.0\n",
            "Epoch 32: Epoch Loss =  5.260910813678342\n",
            " 100.0\n",
            "Epoch 33: Epoch Loss =  5.273581849828518\n",
            " 100.0\n",
            "Epoch 34: Epoch Loss =  4.821910052366742\n",
            " 100.0\n",
            "Epoch 35: Epoch Loss =  4.922953526761765\n",
            " 100.0\n",
            "Epoch 36: Epoch Loss =  4.928821050759695\n",
            " 100.0\n",
            "Epoch 37: Epoch Loss =  4.903382399960722\n",
            " 100.0\n",
            "Epoch 38: Epoch Loss =  4.910829289270866\n",
            " 100.0\n",
            "Epoch 39: Epoch Loss =  5.0744968053652855\n",
            " 100.0\n",
            "Epoch 40: Epoch Loss =  4.910023192610937\n",
            " 100.0\n",
            "Epoch 41: Epoch Loss =  5.005041322784143\n",
            " 100.0\n",
            "Epoch 42: Epoch Loss =  4.974615220304357\n",
            " 100.0\n",
            "Epoch 43: Epoch Loss =  4.965317418737546\n",
            " 100.0\n",
            "Epoch 44: Epoch Loss =  4.841997601703805\n",
            " 100.0\n",
            "Epoch 45: Epoch Loss =  4.970612839371935\n",
            " 100.0\n",
            "Epoch 46: Epoch Loss =  4.623089573414029\n",
            " 100.0\n",
            "Epoch 47: Epoch Loss =  4.784321639331698\n",
            " 100.0\n",
            "Epoch 48: Epoch Loss =  4.825310293603426\n",
            " 100.0\n",
            "Epoch 49: Epoch Loss =  4.770307608206238\n",
            " 100.0\n",
            "Epoch 50: Epoch Loss =  4.6171495631514405\n",
            " 100.0\n",
            "Epoch 51: Epoch Loss =  4.752712849909948\n",
            " 100.0\n",
            "Epoch 52: Epoch Loss =  4.97141775798973\n",
            " 100.0\n",
            "Epoch 53: Epoch Loss =  4.545245933883545\n",
            " 100.0\n",
            "Epoch 54: Epoch Loss =  4.884950213873774\n",
            " 100.0\n",
            "Epoch 55: Epoch Loss =  4.800179096832369\n",
            " 100.0\n",
            "Epoch 56: Epoch Loss =  4.80090098069388\n",
            " 100.0\n",
            "Epoch 57: Epoch Loss =  4.788952981000441\n",
            " 100.0\n",
            "Epoch 58: Epoch Loss =  4.890564551619501\n",
            " 100.0\n",
            "Epoch 59: Epoch Loss =  4.532928055904161\n",
            " 100.0\n",
            "Epoch 60: Epoch Loss =  4.890393678628909\n",
            " 100.0\n",
            "Epoch 61: Epoch Loss =  4.812909279080127\n",
            " 100.0\n",
            "Epoch 62: Epoch Loss =  4.724514293378295\n",
            " 100.0\n",
            "Epoch 63: Epoch Loss =  4.6869294848228655\n",
            " 100.0\n",
            "Epoch 64: Epoch Loss =  4.83954859730658\n",
            " 100.0\n",
            "Epoch 65: Epoch Loss =  4.795635012609691\n",
            " 100.0\n",
            "Epoch 66: Epoch Loss =  4.629386539424146\n",
            " 100.0\n",
            "Epoch 67: Epoch Loss =  4.769526232468578\n",
            " 100.0\n",
            "Epoch 68: Epoch Loss =  4.744015174739424\n",
            " 100.0\n",
            "Epoch 69: Epoch Loss =  4.7812676586569784\n",
            " 100.0\n",
            "Epoch 70: Epoch Loss =  4.737247494826794\n",
            " 100.0\n",
            "Epoch 71: Epoch Loss =  4.781477303753449\n",
            " 100.0\n",
            "Epoch 72: Epoch Loss =  4.634388928439703\n",
            " 100.0\n",
            "Epoch 73: Epoch Loss =  4.850030964395884\n",
            " 100.0\n",
            "Epoch 74: Epoch Loss =  4.7492460889599935\n",
            " 100.0\n",
            "Epoch 75: Epoch Loss =  4.797982036279507\n",
            " 100.0\n",
            "Epoch 76: Epoch Loss =  4.688272825576717\n",
            " 100.0\n",
            "Epoch 77: Epoch Loss =  4.624209895973042\n",
            " 100.0\n",
            "Epoch 78: Epoch Loss =  4.435148506655714\n",
            " 100.0\n",
            "Epoch 79: Epoch Loss =  4.881162824882166\n",
            " 100.0\n",
            "Epoch 80: Epoch Loss =  4.661345577087964\n",
            " 100.0\n",
            "Epoch 81: Epoch Loss =  4.643589663526019\n",
            " 100.0\n",
            "Epoch 82: Epoch Loss =  4.698851441851721\n",
            " 100.0\n",
            "Epoch 83: Epoch Loss =  4.548365364004541\n",
            " 100.0\n",
            "Epoch 84: Epoch Loss =  4.871214530004599\n",
            " 100.0\n",
            "Epoch 85: Epoch Loss =  4.634545396983733\n",
            " 100.0\n",
            "Epoch 86: Epoch Loss =  4.597870638699417\n",
            " 100.0\n",
            "Epoch 87: Epoch Loss =  4.666909649706851\n",
            " 100.0\n",
            "Epoch 88: Epoch Loss =  4.594566399663742\n",
            " 100.0\n",
            "Epoch 89: Epoch Loss =  4.469447230298705\n",
            " 100.0\n",
            "Epoch 90: Epoch Loss =  4.364736484548637\n",
            " 100.0\n",
            "Epoch 91: Epoch Loss =  4.714130557005863\n",
            " 100.0\n",
            "Epoch 92: Epoch Loss =  4.63266745262684\n",
            " 100.0\n",
            "Epoch 93: Epoch Loss =  4.723598990566083\n",
            " 100.0\n",
            "Epoch 94: Epoch Loss =  4.699054186345609\n",
            " 100.0\n",
            "Epoch 95: Epoch Loss =  4.549835195348425\n",
            " 100.0\n",
            "Epoch 96: Epoch Loss =  4.666590079957177\n",
            " 100.0\n",
            "Epoch 97: Epoch Loss =  4.57934254321783\n",
            " 100.0\n",
            "Epoch 98: Epoch Loss =  4.508042483163129\n",
            " 100.0\n",
            "Epoch 99: Epoch Loss =  4.545776486937653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gcm132U1E5l"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJy9iaw-twzu",
        "outputId": "70bad821-6670-4113-d3e6-40354a891d9b"
      },
      "source": [
        "preprocess_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.to(device)),\n",
        "    # transforms.Lambda(lambda x: x.unsqueeze(0))\n",
        "])\n",
        "lion = Image.open('drive/MyDrive/images/style/1/lion.jpg')\n",
        "model_in = preprocess_test(lion)\n",
        "model = Encoder_Decoder(enc, dec).to(device)\n",
        "model.load_state_dict(torch.load('enc_dec_model'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXQHT28hvN2d"
      },
      "source": [
        "op = model(model_in)\n",
        "save_image(model_in, 'test_in.jpg')\n",
        "save_image(op, 'test_out.jpg')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcHaWYubvtQG"
      },
      "source": [
        "loss = ContentStyleLoss()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYaReYphv31e"
      },
      "source": [
        "content_in = model.encoder(model_in)\n",
        "content_out = model.encoder(op)\n",
        "styles_in = model.style_features[:4]\n",
        "styles_out = model.style_features[4:]\n",
        "l = loss(content_in, content_out, styles_in, styles_out)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICdpbwwawK3u",
        "outputId": "7e6b49b7-7e08-4049-8cb2-73f5c3e29bd7"
      },
      "source": [
        "print(l.item())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1310.5318603515625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S-_C2eMwL0M"
      },
      "source": [
        "test_images = DataLoader(ImageFolder('drive/MyDrive/images/content', transform=preprocess_test), batch_size=1, shuffle=True, num_workers=0)\n",
        "x = 1\n",
        "for i in test_images:\n",
        "  i = i[0]\n",
        "  # print(i.shape)\n",
        "  decoded = model(i)\n",
        "  content_in = model.encoder(i)\n",
        "  content_out = model.encoder(decoded)\n",
        "  styles_in = model.style_features[:4]\n",
        "  styles_out = model.style_features[4:]\n",
        "\n",
        "  l = loss(content_in, content_out, styles_in, styles_out)\n",
        "\n",
        "  save_image(i, f'in_{x}.jpg')\n",
        "  save_image(decoded, f'out{x}.jpg')\n",
        "  x += 1\n",
        "  del content_in, content_out, styles_in, styles_out\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEHPm7N4ykCc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}